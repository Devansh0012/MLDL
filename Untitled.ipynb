{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d42db1f-bc4f-4e58-92ca-c46487e42faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6110afc5-5bd8-42d2-8711-56d9472bb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, max_frames=20):\n",
    "    cap = cv2.VideoCapture('fight_0117.mpeg')\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame_count == max_frames:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (224, 224))  # Resize frame for ResNet\n",
    "        frames.append(frame)\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "    return np.array(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d812ae-e4db-40b1-900c-8e761c98653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(video_folder, labels):\n",
    "    X = []\n",
    "    y = []\n",
    "    for label in labels:\n",
    "        label_folder = os.path.join(video_folder, label)\n",
    "        for video in os.listdir(label_folder):\n",
    "            video_path = os.path.join(label_folder, video)\n",
    "            frames = extract_frames(video_path)\n",
    "            X.append(frames)\n",
    "            y.append(1 if label == 'fight' else 0)  # 1 for fight, 0 for non-fight\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "video_folder = './cctv_violence_data/'  # Folder containing fight and non-fight subfolders\n",
    "X, y = load_data(video_folder, labels=['fight', 'non_fight'])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4e7139-eea0-4d63-b108-2144ac3f3b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    # ResNet50 Pre-trained Model for Feature Extraction\n",
    "    resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    resnet.trainable = False  # Freeze ResNet layers\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.TimeDistributed(resnet, input_shape=(20, 224, 224, 3)))  # 20 frames\n",
    "    model.add(tf.keras.layers.TimeDistributed(GlobalAveragePooling2D()))\n",
    "    \n",
    "    # LSTM to capture temporal information\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification (fight vs non-fight)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48333109-295b-496c-9f85-4da68a5d6525",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Training data contains 1 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_slicing.py:492\u001b[0m, in \u001b[0;36mtrain_validation_split\u001b[1;34m(arrays, validation_split)\u001b[0m\n\u001b[0;32m    489\u001b[0m split_at \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mfloor(batch_dim \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m validation_split)))\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split_at \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m split_at \u001b[38;5;241m==\u001b[39m batch_dim:\n\u001b[1;32m--> 492\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    493\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data contains \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples, which is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msufficient to split it into a validation and training set as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified by `validation_split=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_split\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovide more data, or a different value for the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_split` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split\u001b[39m(t, start, end):\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Training data contains 1 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7130c-333d-43fa-ad8f-f0339ea07206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
